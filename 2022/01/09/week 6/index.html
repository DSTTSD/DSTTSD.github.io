<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"dsttsd.github.io","root":"/","images":"/images","scheme":"Pisces","darkmode":false,"version":"8.8.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>
<meta name="description" content="week 6 内容：  louis philippe morency 《多模态机器学习》 35% 论文阅读：  DeepCoclustering AutoRec: Autoencoders Meet Collaborative Filtering AugGAN：Cross Domain Adaptation with GAN based DataAugmentation   D">
<meta property="og:type" content="article">
<meta property="og:title" content="第六次周报">
<meta property="og:url" content="https://dsttsd.github.io/2022/01/09/week%206/index.html">
<meta property="og:site_name" content="DSTの杂货铺">
<meta property="og:description" content="week 6 内容：  louis philippe morency 《多模态机器学习》 35% 论文阅读：  DeepCoclustering AutoRec: Autoencoders Meet Collaborative Filtering AugGAN：Cross Domain Adaptation with GAN based DataAugmentation   D">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://s2.loli.net/2021/12/29/IVcB2K56R9LFMeG.png">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=U%3D%5C%7B1%2C...%2Cm+%5C%7D">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=I%3D%5C%7B1%2C...%2Cn+%5C%7D">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=R+%5Cin+%5Cmathcal%7BR%7D%5E%7Bm+%5Ctimes+n%7D">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=h%5Cleft%28+%5Cmathbf%7Br%7D%3B%5Ctheta+%5Cright%29%3Df%5Cleft%28+%5Cmathbf%7BW%7D+%5Ccdot+g%5Cleft%28+%5Cmathbf%7BVr%7D%2B%5Cmu+%5Cright%29+%2Bb+%5Cright%29">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=f%5Cleft%28+%5Ccdot+%5Cright%29">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=g%5Cleft%28+%5Ccdot+%5Cright%29">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=%5Ctheta+%3D+%5Cleft%5C%7B+%5Cmathbf%7BW%7D%2C%5Cmathbf%7BV%7D%2C%5Cmathbf%7B%5Cmu%7D%2Cb+%5Cright%5C%7D">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=%5Cmathbf%7BW%7D+%5Cin+%5Cmathbb%7BR%7D%5E%7Bd%5Ctimes+k%7D">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=%5Cmathbf%7BV%7D+%5Cin+%5Cmathbb%7BR%7D%5E%7Bk%5Ctimes+d%7D">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=%5Cmu+%5Cin+%5Cmathbb%7BR%7D%5Ek">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=b+%5Cin+%5Cmathbb%7BR%7D%5Ed">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=m">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=n">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=k">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=%5Cmathop%7Bmin%7D%5Climits_%7B%5Ctheta%7D+%5Csum_%7B%5Cmathbf%7Br%7D+%5Cin+%5Cmathbf%7BS%7D%7D%7B+%5ClVert+%5Cmathbb%7Br%7D-h%5Cleft%28+%5Cmathbf%7Br%7D%3B%5Ctheta+%5Cright%29+%5CrVert%7D_2%5E2">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=%5Cmathop%7Bmin%7D%5Climits_%7B%5Ctheta%7D+%5Csum_%7Bi%3D1%7D%5En%7B+%5ClVert+%5Cmathbb%7Br%7D%5E%7B%28i%29%7D-h%5Cleft%28+%5Cmathbf%7Br%7D%5E%7B%28i%29%7D%3B%5Ctheta+%5Cright%29%5CrVert%7D_%7B%5Cmathcal%7BO%7D%7D%5E2+%2B%5Cfrac%7B%5Clambda%7D%7B2%7D%5Ccdot+%5Cleft%28+%5ClVert+%5Cmathbf%7BW%7D%5CrVert_F%5E2+%2B%5ClVert+%5Cmathbf%7BV%7D%5CrVert_F%5E2++%5Cright%29">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=%5ClVert+%5Ccdot%5CrVert_F">
<meta property="og:image" content="https://pic3.zhimg.com/80/v2-f34b01b4a9b37014e3fe77e37cca5b3a_720w.jpg">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=I-autorec">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=U-autorec">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=I-autorec">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=U-autorec">
<meta property="og:image" content="https://pic3.zhimg.com/80/v2-dde91dabff84db3086a4c8b761e46eb6_720w.jpg">
<meta property="og:image" content="https://pic4.zhimg.com/80/v2-f7691582129c9cdec1c3e454ebd80cf7_720w.jpg">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20181101160051217.JPG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xldmlvcGt1,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20181026131632437.JPG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xldmlvcGt1,size_27,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/2018110116401050.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xldmlvcGt1,size_16,color_FFFFFF,t_70">
<meta property="article:published_time" content="2022-01-09T06:07:08.000Z">
<meta property="article:modified_time" content="2022-06-28T04:08:03.165Z">
<meta property="article:author" content="DST">
<meta property="article:tag" content="周报">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s2.loli.net/2021/12/29/IVcB2K56R9LFMeG.png">


<link rel="canonical" href="https://dsttsd.github.io/2022/01/09/week%206/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://dsttsd.github.io/2022/01/09/week%206/","path":"2022/01/09/week 6/","title":"第六次周报"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>第六次周报 | DSTの杂货铺</title>
  




  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">DSTの杂货铺</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">学习笔记</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li>
        <li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">3</span></a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">3</span></a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">11</span></a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#deepcoclusteringsdm-2019"><span class="nav-number">1.</span> <span class="nav-text">DeepCoclustering（SDM 2019）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%BB%E8%A6%81%E5%86%85%E5%AE%B9"><span class="nav-number">1.1.</span> <span class="nav-text">主要内容</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BC%98%E5%8C%96%E7%9B%AE%E6%A0%87"><span class="nav-number">1.2.</span> <span class="nav-text">优化目标</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#cluster-assignment"><span class="nav-number">1.2.1.</span> <span class="nav-text">cluster assignment</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#instance-feature-cross-loss"><span class="nav-number">1.2.2.</span> <span class="nav-text">Instance-Feature Cross Loss</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%95%B4%E4%BD%93loss"><span class="nav-number">1.2.3.</span> <span class="nav-text">整体loss</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#autorec-autoencoders-meet-collaborative-filteringwww-2015"><span class="nav-number">2.</span> <span class="nav-text">AutoRec: Autoencoders Meet Collaborative Filtering（WWW 2015）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#cyclegan-iccv-2017"><span class="nav-number">3.</span> <span class="nav-text">CycleGAN（ ICCV 2017）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#auggan%E5%9F%BA%E4%BA%8Egan%E7%9A%84%E5%9B%BE%E5%83%8F%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BAeccv-2018"><span class="nav-number">4.</span> <span class="nav-text">AugGAN：基于GAN的图像数据增强（ECCV 2018）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%BB%E8%A6%81%E5%86%85%E5%AE%B9-1"><span class="nav-number">4.1.</span> <span class="nav-text">主要内容</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#loss-%E8%AE%BE%E8%AE%A1"><span class="nav-number">4.2.</span> <span class="nav-text">loss 设计</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%BF%81%E7%A7%BB%E6%95%88%E6%9E%9C"><span class="nav-number">4.3.</span> <span class="nav-text">迁移效果</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="DST"
      src="https://avatars.githubusercontent.com/u/50662067?s=400&u=b552d8b742d1e685ed0ddcc6a97d9f697535fa6b&v=4">
  <p class="site-author-name" itemprop="name">DST</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">11</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/DSTTSD" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;DSTTSD" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
  </div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://dsttsd.github.io/2022/01/09/week%206/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://avatars.githubusercontent.com/u/50662067?s=400&u=b552d8b742d1e685ed0ddcc6a97d9f697535fa6b&v=4">
      <meta itemprop="name" content="DST">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="DSTの杂货铺">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          第六次周报
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-01-09 14:07:08" itemprop="dateCreated datePublished" datetime="2022-01-09T14:07:08+08:00">2022-01-09</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2022-06-28 12:08:03" itemprop="dateModified" datetime="2022-06-28T12:08:03+08:00">2022-06-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%91%A8%E6%8A%A5/" itemprop="url" rel="index"><span itemprop="name">周报</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p>week 6 内容：</p>
<ul>
<li><p>louis philippe morency 《多模态机器学习》 35%</p></li>
<li><p>论文阅读：</p>
<ol type="1">
<li>DeepCoclustering</li>
<li>AutoRec: Autoencoders Meet Collaborative Filtering</li>
<li>AugGAN：Cross Domain Adaptation with GAN based DataAugmentation</li>
</ol></li>
</ul>
<h3 id="deepcoclusteringsdm-2019">DeepCoclustering（SDM 2019）</h3>
<h4 id="主要内容">主要内容</h4>
<figure>
<img src="https://s2.loli.net/2021/12/29/IVcB2K56R9LFMeG.png" alt="" /><figcaption>framework</figcaption>
</figure>
<p>这篇文章提出了一种深度学习框架下的共聚类（co-clustering）方法，在聚类精度上超过了其他传统方法。</p>
<p>其中X代表instance（行，对应user)， Y代表features(列，对应item)， 分别进入Autoencoders进行降维（先进行pretrain 1000 epoch，然后利用encoder接入后面network进行端到端训练），将结果输入inference network（一个multi-layer neural network), 利用GMM框架进行cluster assignment。</p>
<h4 id="优化目标">优化目标</h4>
<h5 id="cluster-assignment">cluster assignment</h5>
<p>参数和概率表示：</p>
<p>inference network：<span class="math inline">\(\eta_{r}\)</span>、<span class="math inline">\(\eta_{c}\)</span> ——》 <span class="math inline">\(Q_{\eta_{r}}(k|h_i)\)</span> <span class="math inline">\(Q_{\eta_{c}}(k|v_j)\)</span> (cluster assignment distributions)</p>
<p>GMM：<span class="math inline">\(\phi_{r}\)</span>、<span class="math inline">\(\phi_{c}\)</span> ——》<span class="math inline">\(P_{\phi_{r}}(k|h_i)\)</span> <span class="math inline">\(P_{\phi_{c}}(k|v_j)\)</span> (cluster assignment posterior)</p>
<p>对于AE输出的隐变量<span class="math inline">\(z_i\)</span>, 进入inference network中的MLN，得到<span class="math inline">\(h_i\)</span>:</p>
<p>​ <span class="math inline">\(\mathbf{h}_{i}=\operatorname{Softmax}\left(M L N\left(\mathbf{z}_{i} ; \eta_{r}\right)\right)\)</span></p>
<p>而后GMM第k个参数：<span class="math inline">\(\phi_{r}=\left\{\pi_{r}^{k}, \mu_{r}^{k}, \Sigma_{r}^{k}\right\}\)</span>,可以被表示为：</p>
<p>​ <span class="math inline">\(\begin{array}{l} \pi_{r}^{k}=N_{r}^{k} / N_{r}, \quad \mu_{r}^{k}=\frac{1}{N_{r}^{k}} \sum_{i=1}^{N_{r}^{k}} h_{i k} \mathbf{h}_{i} \\ \Sigma_{r}^{k}=\frac{1}{N_{r}^{k}} \sum_{i=1}^{N_{r}} h_{i k}\left(\mathbf{h}_{i}-\mu_{r}^{k}\right)\left(\mathbf{h}_{i}-\mu_{r}^{k}\right)^{T} \end{array}\)</span></p>
<p>其中<span class="math inline">\(N_{r}\)</span>是instance的数目（即user），<span class="math inline">\(N_{r}^{k}\)</span>是所有instance对应 <span class="math inline">\(h_i\)</span>的 k-dim的和，这样第i个instance分配给第k个cluster的概率可以表示为：</p>
<p>​ <span class="math inline">\(\gamma_{r(i)}^{k}=\frac{\pi_{r}^{k} \mathcal{N}\left(\mathbf{h}_{i} \mid \mu_{r}^{k}, \Sigma_{r}^{k}\right)}{\sum_{k^{\prime}=1}^{g} \pi_{r}^{k^{\prime}} \mathcal{N}\left(\mathbf{h}_{i} \mid \mu_{r}^{k^{\prime}}, \Sigma_{r}^{k^{\prime}}\right)}\)</span></p>
<p>似然函数（取<span class="math inline">\(\gamma_{r(i)}^{k}\)</span>上边求和）：</p>
<p>​ <span class="math inline">\(\log \left\{\prod_{i=1}^{N_{r}} P_{\phi_{r}}\left(\mathbf{h}_{i}\right)\right\}=\sum_{i=1}^{N_{r}} \log P_{\phi_{r}}\left(\mathbf{h}_{i}\right)=\sum_{i=1}^{N_{r}} \log \left\{\sum_{k=1}^{K} \pi_{r}^{k} \mathcal{N}\left(\mathbf{h}_{i} \mid \mu_{r}^{k}, \Sigma_{r}^{k}\right)\right\}\)</span></p>
<p>DeepCC并没有直接进行MLE，而是最大化变分lower bound，有两点优势：</p>
<ol type="1">
<li><p>通过最小化Q P之间的KL散度，让GMM更准确</p></li>
<li><p>与对数似然绑定，让训练过程更加effective</p>
<p>lower bound:</p></li>
</ol>
<p>​ <span class="math inline">\(\begin{array}{l} \sum_{i=1}^{N_{r}} \log P\left(\mathbf{h}_{i}\right)=\sum_{i=1}^{N_{r}} \log \int_{k} P\left(k, \mathbf{h}_{i}\right) \\ =\sum_{i=1}^{N_{r}} \log \int_{k} \frac{P\left(k, \mathbf{h}_{i}\right)}{Q\left(k \mid \mathbf{h}_{i}\right)} Q\left(k \mid \mathbf{h}_{i}\right) \\ =\sum_{i=1}^{N_{r}} \log \left(E_{Q}\left[\frac{P\left(k, \mathbf{h}_{i}\right)}{Q\left(k \mid \mathbf{h}_{i}\right)}\right]\right) \\ \geq \sum_{i=1}^{N_{r}} E_{Q}\left[\log \frac{P\left(k, \mathbf{h}_{i}\right)}{Q\left(k \mid \mathbf{h}_{i}\right)}\right] \\ =\sum_{i=1}^{N_{r}}\left\{E_{Q}\left[\log P\left(k, \mathbf{h}_{i}\right)\right]+H\left(k \mid \mathbf{h}_{i}\right)\right\} \\ =\mathcal{L}_{r} \end{array}\)</span></p>
<p>中间把log拿入期望使用了jensen ‘s inequality</p>
<p>更进一步，可以得到Q与P之间KL散度与lower bound关系(第二步减了一个<span class="math inline">\(logP(h_i)\)</span>，又加了一个)：</p>
<p><span class="math inline">\(\begin{array}{l} \mathcal{L}_{r}=\sum_{i=1}^{N_{r}}\left\{E_{Q}\left[\log P\left(k, \mathbf{h}_{i}\right)\right]-E_{Q}\left(\log Q\left(k \mid \mathbf{h}_{i}\right)\right)\right\} \\ =\sum_{i=1}^{N_{r}}\left\{\int_{k} Q\left(k \mid \mathbf{h}_{i}\right) \log \frac{P\left(k, \mathbf{h}_{i}\right)}{Q\left(k \mid \mathbf{h}_{i}\right)}-\right. \left.\int_{k} Q\left(k \mid \mathbf{h}_{i}\right) \log P\left(\mathbf{h}_{i}\right)+\log P\left(\mathbf{h}_{i}\right)\right\} \\ =\sum_{i=1}^{N_{r}}\left\{\int_{k} Q\left(k \mid \mathbf{h}_{i}\right) \log \frac{P\left(k, \mathbf{h}_{i}\right)}{Q\left(k \mid \mathbf{h}_{i}\right) P\left(\mathbf{h}_{i}\right)}+\log P\left(\mathbf{h}_{i}\right)\right\} \\ =\sum_{i=1}^{N_{r}}\left\{\int_{k} Q\left(k \mid \mathbf{h}_{i}\right) \log \frac{P\left(k \mid \mathbf{h}_{i}\right)}{Q\left(k \mid \mathbf{h}_{i}\right)}+\log P\left(\mathbf{h}_{i}\right)\right\} \\ =\sum_{i=1}^{N_{r}}\left\{-K L\left(Q\left(k \mid \mathbf{h}_{i}\right) \| P\left(k \mid \mathbf{h}_{i}\right)\right)+\log P\left(\mathbf{h}_{i}\right)\right\} \end{array}\)</span></p>
<p>对应可以得到feature的assignment loss：</p>
<p><span class="math inline">\(\mathcal{L}_{c}=\sum_{j=1}^{N_{c}}\left\{E_{Q}\left[\log P\left(k, \mathbf{v}_{j}\right)\right]-E_{Q}\left(\log Q\left(k \mid \mathbf{v}_{j}\right)\right)\right\}\)</span></p>
<h5 id="instance-feature-cross-loss">Instance-Feature Cross Loss</h5>
<p>对联合概率<span class="math inline">\(P(X,Y)\)</span>设计loss进行优化</p>
<p>assignment到cluster的概率：</p>
<p>instance: <span class="math inline">\(\gamma_{r(i)}=\left(\gamma_{r(i)}^{1}, \cdots, \gamma_{r(i)}^{g}\right)^{T}\)</span></p>
<p>feature：<span class="math inline">\(\gamma_{c(i)}=\left(\gamma_{c(i)}^{1}, \cdots, \gamma_{c(i)}^{g}\right)^{T}\)</span></p>
<p>第i个instance和第j个instance的联合概率（划分前）表示为：</p>
<p><span class="math inline">\(p\left(\mathbf{x}_{i}, \mathbf{y}_{j}\right)=\mathcal{J}\left(\boldsymbol{\gamma}_{r(i)}, \boldsymbol{\gamma}_{c(j)}\right)\)</span></p>
<p>第s个instance cluster和第t个feature cluster的联合概率（划分后）为：</p>
<p><span class="math inline">\(p\left(\hat{\mathbf{x}}_{s}, \hat{\mathbf{y}}_{t}\right)=\sum\left\{p\left(\mathbf{x}_{i}, \mathbf{y}_{j}\right) \mid \mathbf{x}_{i} \in \hat{\mathbf{x}}_{s}, \mathbf{y}_{j} \in \hat{\mathbf{y}}_{t}\right\}\)</span></p>
<p>在论文中，作者使用点积来表示<span class="math inline">\(\mathcal{J}\)</span>,其实是可以尝试改变的。这样做的原因有两点：</p>
<ol type="1">
<li>大部分co-cluster， instance cluster以及feature cluster 数量是相等的</li>
<li>相近的instance 有着相似的 feature</li>
</ol>
<p>各自的互信息：</p>
<p><span class="math inline">\(I(X ; Y)=\sum_{\mathbf{x}_{i}} \sum_{\mathbf{y}_{j}} p\left(\mathbf{x}_{i}, \mathbf{y}_{j}\right) \log \frac{p\left(\mathbf{x}_{i}, \mathbf{y}_{j}\right)}{p\left(\mathbf{x}_{i}\right) p\left(\mathbf{y}_{j}\right)}\)</span></p>
<p><span class="math inline">\(I(\hat{X} ; \hat{Y})=\sum_{\hat{\mathbf{x}}_{s}} \sum_{\hat{\mathbf{y}}_{t}} p\left(\hat{\mathbf{x}}_{s}, \hat{\mathbf{y}}_{t}\right) \log \frac{p\left(\hat{\mathbf{x}}_{s}, \hat{\mathbf{y}}_{t}\right)}{p\left(\hat{\mathbf{x}}_{s}\right), p\left(\hat{\mathbf{y}}_{t}\right)}\)</span></p>
<p>互信息之间的差：<span class="math inline">\(I(X ; Y)-I(\hat{X} ; \hat{Y})\)</span></p>
<p><span class="math inline">\(\begin{array}{l} =\sum_{\hat{\mathbf{x}}_{s}} \sum_{\hat{\mathbf{y}}_{t}} \sum_{\mathbf{x}_{i} \in \hat{\mathbf{x}}_{s}} \sum_{\mathbf{y}_{j} \in \hat{\mathbf{y}}_{t}} p\left(\mathbf{x}_{i}, \mathbf{x}_{j}\right) \log \frac{p\left(\mathbf{x}_{i}, \mathbf{x}_{j}\right)}{p\left(\mathbf{x}_{i}\right) p\left(\mathbf{x}_{j}\right)} \\ -\sum_{\hat{\mathbf{x}}_{s}} \sum_{\hat{\mathbf{y}}_{t}}\left(\sum_{\mathbf{x}_{i} \in \hat{\mathbf{x}}_{s}} \sum_{\mathbf{y}_{j} \in \hat{\mathbf{y}}_{t}} p\left(\mathbf{x}_{i}, \mathbf{y}_{j}\right)\right) \log \frac{p\left(\hat{\mathbf{x}}_{s}, \hat{\mathbf{y}}_{t}\right)}{p\left(\hat{\mathbf{x}}_{s}\right) p\left(\hat{\mathbf{y}}_{t}\right)} \\ =\sum_{\hat{\mathbf{x}}_{s}} \sum_{\hat{\mathbf{y}}_{t}} \sum_{\mathbf{x}_{i} \in \hat{\mathbf{x}}_{s}} \sum_{\mathbf{y}_{j} \in \hat{\mathbf{y}}_{t}} p\left(\mathbf{x}_{i}, \mathbf{y}_{j}\right) \log \frac{p\left(\mathbf{x}_{i}, \mathbf{y}_{j}\right)}{q\left(\mathbf{x}_{i}, \mathbf{y}_{j}\right)} \\ =K L(p(X, Y) \| q(X, Y)) \\ \geq 0 \end{array}\)</span></p>
<p>因此为了让差最小化（划分后损失最少），设计loss为：</p>
<p>​ <span class="math inline">\(1-\frac{I(\hat{X} ; \hat{Y})}{I(X ; Y)}\)</span></p>
<h5 id="整体loss">整体loss</h5>
<p>综合上述loss：</p>
<p><span class="math inline">\(\begin{array}{c}  \quad \min _{\theta_{r}, \theta_{c}, \eta_{r}, \eta_{c}} J=J_{1}+J_{2}+J_{3} \\ J_{1}=\frac{\lambda_{1}}{n} \sum_{i=1}^{n} l\left(\mathbf{x}_{i}, g_{r}\left(\mathbf{z}_{i}\right)\right)+\lambda_{2} P_{a e}\left(\theta_{r}\right)+\lambda_{3}\left(-\mathcal{L}_{r}\right)+P_{i n f}\left(\Sigma_{r}\right) \\ J_{2}=\frac{\lambda_{1}}{d} \sum_{j=1}^{i} l\left(\mathbf{y}_{j}, g_{c}\left(\mathbf{w}_{j}\right)\right)+\lambda_{2} P_{a e}\left(\theta_{c}\right)+\lambda_{3}\left(-\mathcal{L}_{c}\right)+P_{\text {inf }}\left(\Sigma_{c}\right) \\ J_{3}=\lambda_{4}\left(1-\frac{I(\hat{X} ; \hat{Y})}{I(X ; X)}\right) \end{array}\)</span></p>
<h3 id="autorec-autoencoders-meet-collaborative-filteringwww-2015">AutoRec: Autoencoders Meet Collaborative Filtering（WWW 2015）</h3>
<p><strong>1、写作动机</strong></p>
<p>2015年前后，深度神经网络在视觉（vision）和对话（speech）数据建模方面取得了显著的突破，该文作者由此产生了把深度神经网络应用到协同过滤模型的想法。该文基于自编码器提出了协同过滤模型AutoRec，并通过实验证明了该模型较此前的基于神经网络的协同过滤模型具有更强的表示能力和更高的计算效率。</p>
<p><strong>2、问题定义</strong></p>
<p>给定用户集合 <img src="https://www.zhihu.com/equation?tex=U%3D%5C%7B1%2C...%2Cm+%5C%7D" alt="[公式]" /> 、物品集合<img src="https://www.zhihu.com/equation?tex=I%3D%5C%7B1%2C...%2Cn+%5C%7D" alt="[公式]" /> 、部分用户-物品评分记录构成的用户-物品评价矩阵<img src="https://www.zhihu.com/equation?tex=R+%5Cin+%5Cmathcal%7BR%7D%5E%7Bm+%5Ctimes+n%7D" alt="[公式]" />，对未知用户-物品评价行为做评分预测，根据均方根误差（RMSE)做评估。</p>
<p>其模型也可以写成重建函数形式：</p>
<p><img src="https://www.zhihu.com/equation?tex=h%5Cleft%28+%5Cmathbf%7Br%7D%3B%5Ctheta+%5Cright%29%3Df%5Cleft%28+%5Cmathbf%7BW%7D+%5Ccdot+g%5Cleft%28+%5Cmathbf%7BVr%7D%2B%5Cmu+%5Cright%29+%2Bb+%5Cright%29" alt="[公式]" /> (1)</p>
<p>其中 <img src="https://www.zhihu.com/equation?tex=f%5Cleft%28+%5Ccdot+%5Cright%29" alt="[公式]" /> 和 <img src="https://www.zhihu.com/equation?tex=g%5Cleft%28+%5Ccdot+%5Cright%29" alt="[公式]" /> 分别为输出层和隐藏层的激活函数，参数集 <img src="https://www.zhihu.com/equation?tex=%5Ctheta+%3D+%5Cleft%5C%7B+%5Cmathbf%7BW%7D%2C%5Cmathbf%7BV%7D%2C%5Cmathbf%7B%5Cmu%7D%2Cb+%5Cright%5C%7D" alt="[公式]" /> , <img src="https://www.zhihu.com/equation?tex=%5Cmathbf%7BW%7D+%5Cin+%5Cmathbb%7BR%7D%5E%7Bd%5Ctimes+k%7D" alt="[公式]" /> , <img src="https://www.zhihu.com/equation?tex=%5Cmathbf%7BV%7D+%5Cin+%5Cmathbb%7BR%7D%5E%7Bk%5Ctimes+d%7D" alt="[公式]" /> , <img src="https://www.zhihu.com/equation?tex=%5Cmu+%5Cin+%5Cmathbb%7BR%7D%5Ek" alt="[公式]" /> , <img src="https://www.zhihu.com/equation?tex=b+%5Cin+%5Cmathbb%7BR%7D%5Ed" alt="[公式]" /> . 对应 <img src="https://www.zhihu.com/equation?tex=m" alt="[公式]" /> 个用户和 <img src="https://www.zhihu.com/equation?tex=n" alt="[公式]" /> 个条目, <img src="https://www.zhihu.com/equation?tex=k" alt="[公式]" /> 维隐藏层。</p>
<p>跟AutoEncoder类似地，其损失函数为</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5Cmathop%7Bmin%7D%5Climits_%7B%5Ctheta%7D+%5Csum_%7B%5Cmathbf%7Br%7D+%5Cin+%5Cmathbf%7BS%7D%7D%7B+%5ClVert+%5Cmathbb%7Br%7D-h%5Cleft%28+%5Cmathbf%7Br%7D%3B%5Ctheta+%5Cright%29+%5CrVert%7D_2%5E2" alt="" /><figcaption>[公式]</figcaption>
</figure>
<p>不过考虑到对模型参数的限制，比如加入L2正则，损失函数变化为：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5Cmathop%7Bmin%7D%5Climits_%7B%5Ctheta%7D+%5Csum_%7Bi%3D1%7D%5En%7B+%5ClVert+%5Cmathbb%7Br%7D%5E%7B%28i%29%7D-h%5Cleft%28+%5Cmathbf%7Br%7D%5E%7B%28i%29%7D%3B%5Ctheta+%5Cright%29%5CrVert%7D_%7B%5Cmathcal%7BO%7D%7D%5E2+%2B%5Cfrac%7B%5Clambda%7D%7B2%7D%5Ccdot+%5Cleft%28+%5ClVert+%5Cmathbf%7BW%7D%5CrVert_F%5E2+%2B%5ClVert+%5Cmathbf%7BV%7D%5CrVert_F%5E2++%5Cright%29" alt="" /><figcaption>[公式]</figcaption>
</figure>
<p>其中 <img src="https://www.zhihu.com/equation?tex=%5ClVert+%5Ccdot%5CrVert_F" alt="[公式]" /> 为Frobenius范数.</p>
<p><strong>3、具体模型</strong></p>
<figure>
<img src="https://pic3.zhimg.com/80/v2-f34b01b4a9b37014e3fe77e37cca5b3a_720w.jpg" alt="" /><figcaption>img</figcaption>
</figure>
<p>如上图所示，该文提出的AutoRec模型采取了最简单的自编码器结构，通过一层神经网络编码输入特征得到隐藏层表示，再通过一层神经网络表示对隐藏层表示做解码还原输入特征。根据输入特征的不同，该模型可分为 <img src="https://www.zhihu.com/equation?tex=I-autorec" alt="[公式]" /> 和 <img src="https://www.zhihu.com/equation?tex=U-autorec" alt="[公式]" /> ：输入特征为用户-物品评价矩阵的行，则为基于物品特征学习的自编码器 <img src="https://www.zhihu.com/equation?tex=I-autorec" alt="[公式]" /> ；输入特征为用户-物品评价矩阵的列，则为基于用户特征学习的自编码器 <img src="https://www.zhihu.com/equation?tex=U-autorec" alt="[公式]" /> 。</p>
<h3 id="cyclegan-iccv-2017">CycleGAN（ ICCV 2017）</h3>
<p>pix2pix使用了pair的data进行训练，然而现实中往往是unpaired-data，CycleGAN就是希望能够在目标域和源域之间，不用建立一对一的映射，就可以完成迁移的训练。</p>
<figure>
<img src="https://pic3.zhimg.com/80/v2-dde91dabff84db3086a4c8b761e46eb6_720w.jpg" alt="" /><figcaption>img</figcaption>
</figure>
<p>做到这一点：</p>
<ol type="1">
<li><p>需要有两个判别器， 分别判断X到Y与Y到X的生成，以及Y到X的生成。</p></li>
<li><p>cycle-consistency loss ，生成器可能会直接生成一张目标域的图像而无视源域图像，因此需要保证能够映射回X</p>
<figure>
<img src="https://pic4.zhimg.com/80/v2-f7691582129c9cdec1c3e454ebd80cf7_720w.jpg" alt="" /><figcaption>img</figcaption>
</figure></li>
</ol>
<h3 id="auggan基于gan的图像数据增强eccv-2018">AugGAN：基于GAN的图像数据增强（ECCV 2018）</h3>
<h4 id="主要内容-1">主要内容</h4>
<p>augGan利用语义分割的结构意识（structure-aware）进行数据域的迁移。与cycleGan等进行风格迁移的image2image translation不同，这篇文章利用结构意识强调生成照片的真实性而非艺术性。</p>
<p>AugGAN的训练数据包含：1. 分割mask；2，不同领域的图像(春天和冬天，白天和黑夜)。</p>
<figure>
<img src="https://img-blog.csdnimg.cn/20181101160051217.JPG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xldmlvcGt1,size_16,color_FFFFFF,t_70" alt="" /><figcaption>img</figcaption>
</figure>
<p>主要结构：</p>
<figure>
<img src="https://img-blog.csdnimg.cn/20181026131632437.JPG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xldmlvcGt1,size_27,color_FFFFFF,t_70" alt="" /><figcaption>img</figcaption>
</figure>
<p>AugGan结构如上图：</p>
<ol type="1">
<li>整体迁移是有方向的，X代表源域图像，Y代表目标域图像。$ E_x, E_y<span class="math inline">\(分别代表X和Y的encoder，将图像降维后会得到特征域Z，Z会对接两个decoder，分别输出预测的分割图\)</span><em>{},</em>{}<span class="math inline">\(，以及生成的fake image\)</span> {X},{Y}$。</li>
<li>augGan使用了cycleGan类似的循环结构，保证循环一致性，<span class="math inline">\(\bar{Y}\)</span>经过<span class="math inline">\(E_y，G_y\)</span>得到重构后的$ X_{rec}<span class="math inline">\(，对\)</span>{X}$同理。</li>
<li>有两个判别器<span class="math inline">\(D_x,D_y\)</span></li>
<li>augGan对于decoder中的残差结构使用了hard-share权重共享，对于上采样的结构使用soft-share</li>
</ol>
<h4 id="loss-设计">loss 设计</h4>
<p>总体loss:</p>
<p><span class="math inline">\(\begin{aligned} \mathcal{L}_{\text {full }} &amp;=\mathcal{L}_{G A N}\left(E_{x}, G_{x}, D_{x}, X, Y\right)+\mathcal{L}_{G A N}\left(E_{y}, G_{y}, D_{y}, Y, X\right) \\ &amp;+\lambda_{\text {cyc }} * \mathcal{L}_{\text {cyc }}\left(E_{x}, G_{x}, E_{y}, G_{y}, X, Y\right) \\ &amp;+\lambda_{\text {seg }} *\left(\mathcal{L}_{\text {seg }}\left(E_{x}, P_{x}, X, \hat{X}\right)+\mathcal{L}_{\text {seg }}\left(E_{y}, P_{y}, Y, \hat{Y}\right)\right) \\ &amp;+\lambda_{\omega} *\left(\mathcal{L}_{\omega_{x}}\left(\omega_{G_{x}}, \omega_{P_{x}}\right)+\mathcal{L}_{\omega_{y}}\left(\omega_{G_{y}}, \omega_{P_{y}}\right)\right) \end{aligned}\)</span></p>
<ol type="1">
<li><p>结构意识（structure-aware）</p>
<p>在转换图像的时候，让模型明白不同位置是什么样的背景(语义特征)有利于迁移，AugGan使用分割的标签来实现。</p>
<p><span class="math inline">\(\begin{aligned} \mathcal{L}_{\text {seg }-x}\left(P_{x}, E_{x}, X, \hat{X}\right) &amp;=\lambda_{\text {seg-L1 }} \mathbb{E}_{x \sim p_{\text {data }(x)}}\left[\left\|P_{x}\left(E_{x}(x)\right)-\hat{x}\right\|_{1}\right] \\ &amp;+\lambda_{\text {seg-crossentropy }} \mathbb{E}_{x \sim p_{\text {data }(x)}}\left[\left\|\log \left(P_{x}\left(E_{x}(x)\right)-\hat{x}\right)\right\|_{1}\right] \end{aligned}\)</span></p>
<p>L1loss以及交叉熵损失</p></li>
<li><p>权值共享</p>
<p>hard-sharing: 完全共享一样的权值</p>
<p>soft-sharing：通过loss进行约束</p>
<p>$ <em>{}(</em>{G}, <em>{P})=-((</em>{G_{x}} <em>{P</em>{x}} /|<em>{G</em>{x}}|<em>{2}|</em>{P_{x}}|_{2})^{2}) $</p></li>
<li><p>循环一致性(Cycle consistency)</p>
<p>生成的图片经过重新编码解码能够还原回原来的图片，这样可以保证P(z|X)不会退化为P(z)（不会随机生成目标域的图像）。</p>
<p><span class="math inline">\(\begin{aligned} \mathcal{L}_{c y c}\left(E_{x}, G_{x}, E_{y}, G_{y}, X, Y\right) &amp;=\mathbb{E}_{x \sim p_{\text {data }(x)}}\left[\left\|G_{y}\left(E_{y}\left(G_{x}\left(E_{x}(x)\right)\right)\right)-\mathrm{x}\right\|_{1}\right] \\ &amp;+\mathbb{E}_{y \sim p_{\text {data }(y)}}\left[\left\|G_{x}\left(E_{x}\left(G_{y}\left(E_{y}(y)\right)\right)\right)-y\right\|_{1}\right] \end{aligned}\)</span></p></li>
<li><p>对抗训练</p></li>
</ol>
<p>​ 论文中对抗训练使用了原始的GanLoss：</p>
<p>​ <span class="math inline">\(\begin{aligned} \mathcal{L}_{G A N_{1}}\left(E_{x}, G_{x}, D_{x}, X, Y\right) &amp;=\mathbb{E}_{y \sim p_{\text {data }(y)}}\left[\log D_{x}(y)\right] \\ &amp;+\mathbb{E}_{x \sim p_{\text {data }(x)}}\left[\log \left(1-D_{x}\left(G_{x}\left(E_{x}(x)\right)\right)\right)\right] \end{aligned}\)</span></p>
<h4 id="迁移效果">迁移效果</h4>
<figure>
<img src="https://img-blog.csdnimg.cn/2018110116401050.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xldmlvcGt1,size_16,color_FFFFFF,t_70" alt="" /><figcaption>img</figcaption>
</figure>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E5%91%A8%E6%8A%A5/" rel="tag"># 周报</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2022/01/01/RL/" rel="prev" title="蘑菇书笔记">
                  <i class="fa fa-chevron-left"></i> 蘑菇书笔记
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2022/01/16/week%207/" rel="next" title="第七次周报">
                  第七次周报 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">DST</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/pisces/" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  
<script src="https://cdn.jsdelivr.net/npm/hexo-generator-searchdb@1.4.0/dist/search.js" integrity="sha256-vXZMYLEqsROAXkEw93GGIvaB2ab+QW6w3+1ahD9nXXA=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>





  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"all","perpage":true,"js":{"url":"https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js","integrity":"sha256-r+3itOMtGGjap0x+10hu6jW/gZCzxHsoKrOd7gyRSGY="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
